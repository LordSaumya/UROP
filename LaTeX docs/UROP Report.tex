\documentclass[fleqn,10pt]{olplainarticle}
% Use option lineno for line numbers 

\usepackage{bibentry}
\nobibliography*

\title{Data-Driven and Physics-Inspired Machine Learning\\[1ex] \large UROP Report U081470}

\author{Saumya Shah}

\keywords{Machine Learning, Symbolic Regression, AI Feynman}

\begin{abstract}
    TK
\end{abstract}

\begin{document}
\maketitle

\flushbottom

\thispagestyle{empty}

\tableofcontents

\section{Introduction}
AI Feynman, a symbolic regression algorithm, is a physics-inspired symbolic regression algorithm developed by Silviu-Marian Udrescu and Max Tegmark in 2020



\section{Background}
TK

\section{Related Work}

\begin{itemize}
    \item \bibentry{udrescu2020}
          \begin{itemize}
              \item Existing solutions use genetic algorithms or sparse regression.
              \item This paper uses NNs to find simplifying factors like symmetry or separability in the dataset.
              \item 6 simplifying assumptions/properties are used:
                    \begin{itemize}
                        \item \emph{Units:} variables have known physical units
                        \item \emph{Low-order polynomials:} $f$ is/composed of low-order polynomial(s)
                        \item \emph{Composition:} $f$ is composed of a small set of elementary functions
                        \item \emph{Smoothness:} $f$ is continuous
                        \item \emph{Symmetry:} some variables in $f$ are symmetric
                        \item \emph{Separability}: $f$ can be separated into sum/product of variables
                    \end{itemize}
              \item Full algorithm (recursive in nature):
                    \begin{enumerate}
                        \item \emph{Dimensional analysis:} Reduces the number of dimensions and simplifies data  (makes the model depend on as few variables as possible).
                        \item \emph{Polynomial fit:} Polynomial coefficients are calculated by solving a system of linear equations and testing if the RMSE is lower than the threshold.
                        \item \emph{Brute force:} Expressions of increasing complexity are generated by brute force and tested till the error drops below a certain threshold.
                        \item \emph{NN-based transformations:} Tests for translational symmetry, separability, equality of variables, and other transformations like power, log, etcetera
                    \end{enumerate}
              \item The key improvement of AI Feynman over Eureqa is its ability to decompose the problem into simpler sub-problems with fewer variables.
          \end{itemize}

    \item \bibentry{Khoo2023.2}
          \begin{itemize}
              \item Physics-inspired symbolic regression methods like AI Feynman leverage properties of $f$ like symmetry and separability.
              \item Four variations of AI Feynman were compared
                    \begin{itemize}
                        \item No additional bias
                        \item Observational bias (replacing angular values with their sines/cosines)
                        \item Inductive bias (search space restriction)
                        \item Both observational and inductive bias
                    \end{itemize}
              \item For experiments 1 and 3, none of the equations on the Pareto frontier matched the orbital equation for Mars.
              \item For experiments 2 and 4, 3 out of 9 equations matched.
              \item Experiment 4 (combining inductive and observational biases) was best suited to rediscover the orbital equation of Mars.
          \end{itemize}

    \item \bibentry{Khoo2023.1}
          \begin{itemize}
              \item This paper extends AI Feynman to discover heliocentricity and planarity of Mars' orbit by adding biases.
              \item Experimental Setup
                    \begin{itemize}
                        \item An inductive bias is built in by restricting the search space to trigonometric, polynomial, and radical functions.
                        \item An observational bias is embedded by replacing angular values with their sine and cosine.
                        \item The description length serves as a measure for fit and parsimony.
                        \item There is a log-scaled penalty on absolute loss (for optimising fit) and on real numbers, operators, and variables (for optimising parsimony)
                    \end{itemize}
              \item Experiment 1
                    \begin{itemize}
                        \item Three sets of observations, corresponding to the three reference frames are created for both coordinate systems (Cartesian and polar) and are used as inputs to AI Feynman.
                        \item For the Cartesian coordinates, several equations were identified that matched a known equation.
                        \item For the polar coordinates, none of them matched any known equations. However, one of the equations uses a similar attempt (using angular width) to a known equation.
                        \item Both coordinate systems preferred heliocentric equations, suggesting a higher parsimony in that reference frame.
                    \end{itemize}
              \item Experiment 2
                    \begin {itemize}
                        \item Principal component analysis is first used to project the data into 3d, 2d, and 1d spaces, which are then used as inputs to AI Feynman.
                        \item None of the equations match the known equation forms. However, two of the equation use a square root to fit $r(t)$ similar to a known equation.
                        \item Most equations only use one to two eigenvectors suggesting a planar relationship.
                    \end{itemize}
              \item Experiment 3
                    \begin{itemize}
                        \item Knowledge regarding the heliocentricity and planarity of Mars' orbit are embedded as observational biases.
                        \item Some of the equations suggest a circular orbit due to low eccentricty.
                        \item After correcting for a vertical shift of focus, Kepler's first law was obtained from both the Cartesian and polar datasets.
                    \end{itemize}
          \end{itemize}
    \item \bibentry{Lemos2023}
          \begin{itemize}
              \item The authors assume Newton's 2nd and 3rd laws as inductive biases and simulate orbital dynamics of solar system bodies using a graph network. 
              Then, they use symbolic regression using an open-source analogue of Eureqa to find an analytic expression for Newton's law of gravitation.
              \item Data of 31 bodies were used from the Horizons On-Line Ephemerys System between 1980 and 2013.
              \item The procedure was composed of two stages: training a graph-network-based simulator on observed data, and then performing symbolic regression.
              \item Graph-Network-Based Simulator
                    \begin{itemize}
                        \item The input is a graph where the nodes represent the celestial bodies and relationships between two bodies are represented as edges.
                        \item Each node contained a trainable scalar $V$ analogous to mass, while each edge stored the spatial displacement vector between the two corresponding bodies.
                        \item The model computed interactions for each body using a function to calculate the values for the edges with a trainable parameter $\theta$, analogous to a force.
                        \item $\theta$ and $v$ are trained using gradient descent using the error between the true and predicted acceleration.
                        \item The graph network uses a 3 layer MLP model implemented in Tensorflow.
                        \item A random three-dimensional rotation was applied to the input graph to prevent biases and to encourage learning rotational equivariance.
                    \end{itemize}
              \item Symbolic Regression
                    \begin{itemize}
                        \item A dataset of force function inputs was created and SR was used to fit an explicit formula for the force function.
                        \item The PySR library was used, which uses a tree search algorithm to produce a set of candidate equations. This was done by assigning a score as the ratio of the increase in accuracy and the increase in complexity.
                    \end{itemize}
              \item Results
                    \begin{itemize}
                        \item The simulator acheived a high degree of accuracy for the accceleration, with an error of 0.2\% on validation data. However, there was a greater uncertainty of 9.1\% for the mass.
                        \item The equivalence principle holds that for bodies which have negligible gravitational influence, their masses are difficult to estimate accurately. As such, these bodies had a higher error in their mass.
                        \item The experiment was able to discover Newton's law of gravity as well as a value very close to the gravitational constant.
                        \item After discovering the form of the interactions between bodies, the edge function was replaced by the discovered expression and retrained to to estimate the mass and gravitational variables, The mean percent error in mass improved to 1.6\%.
                    \end{itemize}
              \item This was only possible due to the inductive biases of Newton's 2nd and 3rd laws.
          \end{itemize}
    \item \bibentry{Brunton2016}
            \begin{itemize}
                \item Symbolic regression using genetic programming is expensive and may be prone to overfitting.
                \item Sparsity techniques efficiently identify the relevant terms to reduce the search space. The resulting model thus balances parsimony with accuracy while also avoiding overfitting.
                \item SINDy leverages the fact that physical systems only have a few relevant terms to promote sparsity.
                \item \emph{Process}:
                    \begin{enumerate}
                        \item A time history of the state is collected and its derivative is numerically approximated. Gaussian noise is added, and the data are organised into two matrices.
                        \item A library of candidate non-linear functions for the state is created for each column of the state matrix.
                        \item A sparse regression problem is set up to determine the vector of coefficients that determine which non-linear terms are in $f$.
                        \item LASSO or other alternative techniques are applied, depending on the context of the problem, to calculate the vector of coefficients.
                    \end{enumerate}
                \item Domain knowledge can be used to help choose appropriate variables and non-linear functions, and to exploit simplifying properties like symmetry.
                \item For the Lorenz system (a system with chaotic dynamics), the model accurately reproduces attractor dynamics, correctly identifies the relevant terms, and determines the coefficients to within 0.03\% of the true value.
                \item The authors further generalise the SINDy method to an example of vortex shedding (fluid dynamics). For the logistic map, parameters are identifed to within 0.1% of true values.
                \item SINDy is robust to measurement noise and unavailability of derivative measurements.
                \item Significant challenges remain in the correct choice of measurement coordinates and the choice of sparsifying function basis.
            \end{itemize}
\end{itemize}

\section{Methodology}
TK

\section{Performance Evaluation}
TK

\section{Conclusion}
TK

\nocite{*}
\bibliography{sample}

\section*{Appendices}
TK

\end{document}